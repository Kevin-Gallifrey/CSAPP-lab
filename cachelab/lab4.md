# Writing a Cache Simulator
一个cache中需要划分set和line，每个cache line要包含valid bit和tag。由于使用LRU策略，对每个line需要一个额外的标志stamp来表示上次使用的时间。  
主函数中使用`getopt()`读取输入的选项参数，并根据cache的大小使用`malloc()`动态开辟内存空间。这里使用了一个二维数组来表示cache，其中第一维表示set，第二维表示line。之后利用`fscanf()`格式化读取trace文件中的内容，得到指令和地址。利用地址对应找到set和line，并判断是否命中。未命中时需要检查有没有空的line，若没有要进行eviction，更新cache。每一次操作cache line都需要更新stamp值。最后free动态分配的内存并打印结果。

动态分配二维数组：先用`**p`得到一维指针数组，对于其中的每一个指针再去动态开辟空间。在回收时，先对指针数组中的每一个指针进行free，在释放p。

# Optimizing Matrix Transpose
根据所给的cache，每个line中包含8个连续的矩阵元素。矩阵在C中是按行连续存储的。为了降低cache miss，采取分块(block)的思想，将一个block放进cache，随后完成block中的所有操作，再换下一个block。  
具体到矩阵转置中，读取`A[0][0]`将`A[0][0]~A[0][7]`都放入cache，对应写入`B[0][0]~B[7][0]`，而此时`B[0][0]~B[0][7], ..., B[7][0]~B[7][7]`都在cache中。那么下一次应该读取`A[1][0]~A[1][7], ..., A[7][0]~A[7][7]`，这样这些数据在写入B时就可以命中缓存。可以发现，若将矩阵划分为8x8的块，每次操作一个块，可以大大降低cache miss。

## 32x32矩阵转置
分成8x8的block，每次对一个block进行转置。对于处理对角线上的block需要另外处理。对于A和B，这些block的第i行都映射到同一个set中。为了避免冲突，在每次读取一行后，位于对角线上的元素要最后赋值给B，这样避免了由于写入B而将原本在cache中的A的数据驱逐出去。

## 64x64矩阵转置
依旧可以先分成8x8的block，但此时会发现block的上半部分和下半部分会映射到相同的set，如果仍和之前一样操作会造成大量的miss。将每个8x8的block分成更小的4x4的block，然后按左上、左下、右下、右上的次序进行。对角线上的block依然需要单独处理，方法类似。  
然而仅仅这样依旧满足不了要求。考虑使用一些局部变量记录矩阵中的元素，这样无需多次加载某些行，减少miss的次数。如对于一个8x8的block，在操作左上的小block时，用变量存储第一行的后4个元素，这样在操作右上的小block时，就不用再取读取第一行，这也就减少了一个cache miss。最后使用了8个变量，记录了两行的后4个元素。

## 61x67矩阵转置
对于cache来说，这是一个不规则的矩阵。但依旧可以用block的思想来处理，依旧可以减少许多cache miss。使用8x8的block无法满足要求，但是使用16x16的block就可以。